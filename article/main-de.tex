\documentclass[paper=a4,11pt,numbers=noenddot]{article}
\linespread{1.2}
\usepackage[parfill]{parskip} % non-indented paragraphs with more space
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[ngerman]{babel}
\usepackage[pdftex]{color,graphicx}

\usepackage[autocite=plain, backend=biber, style=numeric, sorting=nyt]{biblatex}
%\addbibresource{main.bib} % The filename of the bibliography
\bibliography{main}
\nocite{*}

\usepackage{listings}
\renewcommand{\lstlistlistingname}{List of Listings}
\lstdefinestyle{mystyle}{
  basicstyle=\ttfamily\scriptsize,
  numbers=none,
  backgroundcolor=\color[rgb]{0.95,0.90,0.90},
  commentstyle=\color[rgb]{0,0.6,0},
  keywordstyle=\color[rgb]{0.2,0.6,1},
  breakatwhitespace=false,
  breaklines=true,
%  captionpos=b,
  keepspaces=true,
%  numbers=left,
%  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}
\lstset{style=mystyle}

\usepackage[plainpages=false,pdfpagelabels,hidelinks]{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=black,
  citecolor=black,
  urlcolor=blue,
}
\urlstyle{same}

%% margins
\oddsidemargin 0cm
\evensidemargin 0cm
\textwidth 16cm
\topmargin 0cm
%\textheight 24.37cm

\title{Terraform Provider Development}
\author{Eckhard Lehmann}

\begin{document}
\maketitle
\tableofcontents

\section{Einleitung}

Hier bei Otto arbeiten wir mit vielen verschiedenen IT-Systemen, z.B. für den Online-Shop, um Bestellungen und Lieferungen zu verarbeiten oder um Kundendaten zu verwalten. Viele davon sind selbst entwickelt und die Services werden verteilt auf on-premise- und cloud Infrastruktur gehostet. Die Zeit für Release- und Deploymentzyklen spielt eine große Rolle, genau wie die Nachvollziehbarkeit von Änderungen. Daher verwenden die meisten Teams sofern möglich \emph{Infrastructure as Code} (\emph{IaC})~\autocite{morris_infrastructure_as_code_2025} und deklaratives Konfigurationsmanagement. In meinem Team werden die meisten Deployments und Infrastrukturänderungen per Terraform~\autocite{noauthor_terraform_nodate} gemacht und die meisten Anwendungsfälle werden durch das existierende Terraform-Ökosystem abgedeckt.

Aber manchmal ist das nicht der Fall. Wir entwickeln und betreiben einen Service zur Verwaltung von Berechtigungen für Topics in dem asynchronen Messaging-System \emph{Apache Kafka} in der \emph{Confluent Cloud}~\autocite{noauthor_apache_kafka_nodate, noauthor_confluent_nodate}. Die Benutzer sind andere Entwicklungsteams in der Firma, die Kafka zum Austausch von Daten und Nachrichten in ihren jeweiligen Systemen benutzen. Sie benutzen größtenteils ebenfalls Terraform für die Deployments dieser Systeme und es bietet sich an, auch die Entitäten in unserem Service damit zu verwalten. Ein offizieller Provider für unser In-House System ist natürlich nicht verfügbar und so haben wir die Gelegenheit einen solchen zu entwickeln.

In diesem Artikel präsentiere ich unsere Erfahrungen mit der Entwicklung von Terraform-Providern anhand eines kleinen, künstlichen Beispiels. Es enthält die extrahierten Erfahrungsschätze unserer In-House Provider-Entwicklung in einer leicht verständlichen Form und ohne In-House Wissen. Abschnitt~\ref{sec:technology-overview} gibt einen kurzen Überblick über die benutzten und notwendigen Technologien. Abschnitt~\ref{sec:simple-rest-api} zeigt die Atrappe einer API, die als ``Backend'' für den Beispiel-Provider benutzt wird und in Abschnitt~\ref{sec:creat-terr-prov} wird der Beispiel-Provider selbst aus zwei Perspektiven vorgestellt. Die Ergebnisse werden letztendlich in Abschnitt~\ref{sec:summary} zusammengefasst. Da der gesamte Text eng verbunden ist mit dem \emph{terraform-provider-example} Github Repository~\autocite{ecky-l_terraform-provider-example_nodate}, bietet es sich an, dieses Repository zu klonen und nebenbei einen Blick darauf zu werfen.

\section{Technologie-Überblick}
\label{sec:technology-overview}

Wie bei den meisten heutigen Aufgaben in der Softwareentwicklung gibt es schon Technologien, Tools und Frameworks, auf die man aufbauen kann. Terraform selber ist in \emph{Go} programmiert und der einfachste Weg ist, \emph{Go} auch für die Provider-Entwicklung zu nutzen\footnote{Terraform kommuniziert mit Providern über RPC, demnach wäre es prinzipiell möglich, jede Programmiersprache zu nutzen, die auch RPC kann, aber ein High-Level SDK gibt es nur für \emph{Go}}. Deshalb enthält dieser Abschnitt eine kurze Einführung in \emph{Go} und das Terraform Ökosystem.

\subsection{Die Programmiersprache Go}
\label{subsec:go-progr-lang}

Go, oder ``golang'' ist eine moderne, allgemeine Programmiersprache und wurde bei Google entwickelt. Sie ist statisch typisiert und wird mit entsprechenden Typenprüfungen vor der Ausführung in Binärcode kompiliert. Dadurch wird schon vor der Ausführung des Programms eine ganze Klasse von Fehlern ausgeschlossen, die mit dynamisch typisierten und interpretierten Programmiersprachen auftreten können. Golang hat seine Wurzeln in C, Pascal/Oberon und Programmiersprachen mit dem \emph{CSP} (\emph{Communicating Sequential Processes}) Konzept, wie Squeak und Alef~\autocite{donovan_go_2016}. Von diesen Sprachen kommt ein interressantes Modell für die Verwaltung konkurrierender Zugriffe, wodurch Go gerade für parallele Programmierung interessant ist.

Die prominenteste und am besten sichtbare Abstammung hat Go von der Programmiersprache \emph{C}, weswegen sie auch als \emph{C des 21. Jahrhunderts} bezeichnet wird. Allerdings ist die Ähnlichkeit nur oberflächlich, unter der Haube hat Go Garbage Collection, Objektorientierung, Speichersicherheit, typensichere Zeiger und Referenzen sowie funktionale Elemente. Außerdem umfasst Go in dem Kommando \verb'go' selbst ein modernes Toolset für Abhängigkeitsverwaltung, Tests, Dokumentations-Erzeugung, Linting und Profiling - kurzum für alle Dinge, die man in der täglichen Nutzung braucht.

Die Webseite \url{https://go.dev/} ist der zentrale Einstiegspunkt für alle Resourcen rund um Golang, inklusive des sehenswerten Tutorials \emph{Tour of Go}. Für die Entwicklung von Terraform Providern lohnt es sich, dieses Tutorial anzuschauen und mit Golang vertraut zu werden, sofern nicht schon geschehen.

\subsection{\emph{Terraform} und sein Ökosystem}
\label{subsec:terr-tool-ecosyst}

Terraform ist ein Werkzeug zur Verwaltung von Infrastructure as Code. Als zentrales Konzept dient der sogenannte \emph{Terraform-State}, eine JSON-Datei mit einer spezifischen Struktur, die den aktuellen Zustand einer bestimmten Infrastruktur in Form ihrer Ressourcen beschreibt. Zusätzlich gibt es eine Sammlung von Ressourcendefinitionen in \verb'.tf'-Dateien innerhalb eines Verzeichnisses, das als \emph{Terraform-Modul} bezeichnet wird.
Um ein solches Modul zu erstellen, werden Dateien mit der Endung \verb'.tf' mit Ressourcendefinitionen in einem Verzeichnis abgelegt.
Als einfaches Beispiel betrachten wir eine Ressourcen-Entität ``Shop-Artikel'' mit bestimmten Attributen:

\begin{lstlisting}
resource "shop_article" "shampoo" {
  name        = "Princess Rosalea"
  description = "Child Shampoo & Conditioner"
}
\end{lstlisting}

In der Realität handelt es sich dabei um Computerressourcen wie Netzwerke, Datenbanken, virtuelle Maschineninstanzen usw.. Terraform-Ressourcen werden verwendet, um Computerinfrastruktur in Cloud-Umgebungen zu beschreiben. Daher ist immer ein Backend beteiligt –in der Regel eine REST-API–, in dem die Logik implementiert ist, um die jeweiligen Ressourcen in der Cloud-Umgebung bereitzustellen.

Der Befehl \verb'terraform' wird verwendet, um die \verb'.tf'-Dateien in einem Verzeichnis einzulesen, die notwendigen Aktionen zum Erstellen der Ressourcen auszuführen (d.h.\ die API-Endpunkte aufzurufen) und den Zustand im Terraform-State zu speichern. Standardmäßig ist dies eine lokale JSON-Datei mit dem Namen \verb'terraform.tfstate'. In der Regel wird das Modul jedoch so konfiguriert, dass der State an einem entfernten Ort gespeichert wird, z.B. in einem Cloud-Speicher-Bucket oder in einer Datenbank. Wann immer Ressourcen erstellt, geändert oder gelöscht werden sollen, genügt es, die entsprechenden Ressourcendefinitionen in den \verb'.tf'-Dateien zu bearbeiten und \verb'terraform' erneut auszuführen. Ein \verb'terraform apply' tut dann drei Dinge:

\begin{enumerate}
\item\label{itm:tf-read} Die aktuellen Ressourcen im Backend abrufen.
\item\label{itm:tf-compare} Einen Drei-Wege-Vergleich zwischen dem aktuellen Status, den abgerufenen realen Ressourcen und den Ressourcendateien (\verb'.tf') durchführen, und anschließend:
  \begin{itemize}
  \item Ressourcen löschen, die im Backend vorhanden sind, aber nicht in den Ressourcendateien definiert sind.
  \item Ressourcen erstellen, die in den Ressourcendateien definiert sind, aber im Backend noch nicht existieren.
  \item Ressourcen anpassen, deren Definition sich in den Ressourcendateien im Vergleich zur vorherigen Definition im Status geändert hat.
  \end{itemize}
\item\label{itm:tf-create-update} Den neuen Status in der Statusdatei speichern.
\end{enumerate}

Terraform stellt seine Funktionalität über eine Kernkomponente bereit, die die \verb'.tf'-Dateien einliest und den Status verwaltet, sowie über eine Reihe von Plugins, die mit verschiedenen Backends interagieren. Diese Plugins werden Provider genannt und stellen die eigentliche Funktionalität des Infrastrukturanagements bereit. Sie sind vom Terraform-Kern entkoppelt und entwickeln sich unabhängig weiter. Provider existieren für alle bekannten Cloud-Anbieter sowie für verschiedene andere Infrastruktur-Dienste, wie zum Beispiel die IAM-Lösung Keycloak~\autocite{team_keycloak_nodate} oder den Secret Manager Vault~\autocite{noauthor_vault_nodate}.

Ein Einstiegspunkt zur Suche nach Terraform-Providern und deren Dokumentation ist die Terraform Provider Registry~\autocite{noauthor_terraform_registry_nodate}. Es gibt zahlreiche Ressourcen zu Terraform, wobei die Hauptanlaufstelle die offizielle Homepage ist~\autocite{noauthor_terraform_nodate}. Eine gute Einführung mit praktischen Beispielen findet sich außerdem in~\autocite{brikman_terraform_2022}.

\section{Ein einfaches REST API Backend}
\label{sec:simple-rest-api}

Der Zweck von Terraform besteht darin, Infrastruktur als Code zu verwalten, d.h. Infrastruktur-Ressourcen zu erstellen, zu ändern und zu löschen. Wie genau diese Ressourcen aussehen, ist nicht streng festgelegt und obliegt der Implementierung des jeweiligen Providers. Bei einem Cloud-Anbieter wie AWS oder GCP können es virtuelle Hardware-Ressourcen oder Firewall- und Berechtigungsregeln sein, während es bei einer Keycloak-Instanz OpenID-Connect-Clients und entsprechende Zugangsdaten sein könnten. Auf einer lokalen Maschine könnten es Dateien im Dateisystem, Dienstverwaltungs-Skripte oder Richtlinien für Mandatory Access Control (z. B. für SELinux) sein.

Um die Dinge einfach zu halten, betrachten wir für diese Demonstration ein einfaches REST-API-Backend, bei dem die Ressourcen Shop-Artikel sind. Darüber hinaus werden wir dieses Backend gar nicht wirklich erstellen, sondern stattdessen nur simulieren. Wiremock~\autocite{noauthor_wiremock_nodate} ist ein leistungsfähiges Tool und eine Bibliothek, deren einziger Zweck es ist, bestimmte Antworten basierend auf bestimmten Eingabemustern zurückzugeben. Normalerweise wird es verwendet, um API-Clients in verschiedenen Programmiersprachen zu testen, wenn das echte API-Backend noch nicht verfügbar ist oder nicht für Tests benutzt werden soll.

\paragraph{Die REST-Ressource \emph{article}}

Unsere REST-API verwaltet eine Ressource namens \emph{article}, die im Wesentlichen einen Online-Shop-Artikel darstellt. Sie enthält eine ID, einen Namen und eine Beschreibung. Artikel können erstellt, über ihre ID abgerufen, aktualisiert und gelöscht werden. Obwohl dies stark vereinfacht ist, reicht es für ein anschauliches Beispiel.

Die Verwaltung unserer REST-Ressource kann als Zustandsmaschine beschrieben werden: Anfangs existiert kein Artikel, also liefert ein \verb'GET'-Aufruf zu einer bestimmten ID, z.B. \emph{1}, den HTTP-Status 404. Dies entspricht dem Zustand $S_0$, oder \emph{Started}. Wenn ein \verb'POST'-Aufruf an den Endpunkt \verb'/articles' erfolgt, wird ein Artikel mit einer bestimmten ID, z.B. \emph{1}, erstellt, und der Zustand der Entität wechselt zu $S_1$, oder \emph{Article added}. Ein \verb'GET'-Aufruf zu \verb'/articles/1' im Zustand $S_1$ liefert den erstellten Artikel zurück.

Nun gibt es zwei Möglichkeiten, den Zustand erneut zu ändern: Ein \verb'PUT'-Aufruf zu \verb'/articles/1' verändert den Artikel und setzt den Zustand auf $S_2$, oder \emph{Article modified}. Nachfolgende \verb'GET'-Aufrufe zu \verb'/articles/1' liefern nun den geänderten Artikel. Ein \verb'DELETE'-Aufruf zu \verb'/articles/1' ``löscht'' den Artikel sowohl in $S_1$ als auch in $S_2$ und setzt den Zustand wieder auf $S_0$ zurück. Weitere Modifikationen oder spezifische Erstellungs-/Aktualisierungsparameter werden hier nicht berücksichtigt.

In Wiremock kann dies als \emph{Scenario} dargestellt werden~\autocite{noauthor_wiremock_stateful_behavior_2025}. Unser Artikel ist ein Kindershampoo, und die entsprechende Datei findet sich~\href{https://github.com/ecky-l/terraform-provider-example/blob/main/src/wiremock/mappings/shampoo.json}{hier} im GitHub-Repository dieses Beispiels~\autocite{ecky-l_terraform-provider-example_nodate}.

Erstellen Sie ein Verzeichnis namens mappings und legen Sie die Datei dort ab. Laden Sie anschließend die Standalone-Binärdatei von der Wiremock-Homepage herunter, platzieren Sie sie neben dem mappings-Verzeichnis und starten Sie Wiremock mit dem Befehl \verb'java -jar wiremock-standalone-<version>.jar'. Sie sollten sehen, dass der Dienst startet und auf Port \verb'8080' lauscht. Anschließend können Sie überprüfen, ob unser neues ``API-Backend'' funktioniert:

\begin{lstlisting}[language=bash]
$ curl -s localhost:8080/articles/1 | jq
{
  "error": "not found"
}
$ curl -sX POST localhost:8080/articles | jq
{
  "id": 1,
  "name": "Princess Rosalea",
  "description": "Child Shampoo & Conditioner"
}
$ curl -s localhost:8080/articles/1 | jq
{
  "id": 1,
  "name": "Princess Rosalea",
  "description": "Child Shampoo & Conditioner."
}
$ curl -sX PUT localhost:8080/articles/1 | jq
{
  "id": 1,
  "name": "Princess Rosalea",
  "description": "Child Shampoo & Conditioner. Soft on the skin, soft on the environment."
}
$ curl -s localhost:8080/articles/1 | jq
{
  "id": 1,
  "name": "Princess Rosalea",
  "description": "Child Shampoo & Conditioner. Soft on the skin, soft on the environment."
}
$ curl -X DELETE localhost:8080/articles/1
$ curl -s localhost:8080/articles/1 | jq
{
  "error": "not found"
}
\end{lstlisting}

Das ist alles was wir brauchen, um die \emph{shop\_article} Resource im Backend darzustellen, die wir in den folgenden Abschnitten brauchen werden.

\section{Entwicklung eines Terraform Provider mit einer Ressource}
\label{sec:creat-terr-prov}

Die Kommunikation zwischen dem Terraform Kern und den Providern funktioniert über eine RPC-Schnittstelle und Callback-Funktionen, die an bestimmten Stellen in der Interaktion der Punkte~\ref{itm:tf-read}-~\ref{itm:tf-create-update} in Abschnitt~\ref{subsec:terr-tool-ecosyst} ausgeführt werden. Diese Interaktionen, die man auch als den ``Terraform Lebenszyklus'' bezeichnen könnte, lassen sich aus zwei Perspektiven betrachten: aus der des Benutzers (in der Dokumentation auch als ``Practitioner'' bezeichnet) und der des Provider-Entwicklers. Im Folgenden werden beide Perspektiven betrachtet, angefangen mit der des Terraform-Benutzers.


Communication between the terraform core and the providers is implemented via an RPC interface and callback functions that are executed at specific points in the interaction~\ref{itm:tf-read}-~\ref{itm:tf-create-update} in Section~\ref{subsec:terr-tool-ecosyst}.

\subsection{Die Perspektive des Anwenders}
\label{subsec:practitioners-view}

Als ``Practitioner'' wird in der Dokumentation des Terraform Plugin Frameworks~\autocite{noauthor_terraform_framework_nodate} häufig die Person bezeichnet, die Infrastruktur als Code in Terraform verwaltet. Er bzw.\ sie hat einen Satz von \verb'.tf'-Dateien in einem Verzeichnis, das ein Terraform-Modul bildet und nutzt die Ressourcen und Datenquellen, die ein Provider bereitstellt. Neben der Pflege dieser Dateien beschäftigt er sich auch mit der Installation und Aktualisierung von Providern, und sein Hauptanliegen ist, dass seine Infrastruktur dabei stabil bleibt. Eine gute Einführung zur Benutzung von Terraform, also der Perspektive des ``Practitioners'', bietet~\autocite{brikman_terraform_2022}. In diesem Abschnitt werden wir die Welt unseres Beispiel-Providers aus seiner Perspektive aussieht.

\subsubsection{Ein Beispiel-Terraform-Modul}
\label{subsubsec:an-example-terraform}

In unserem Beispiel gibt es ein Terraform-Modul (Verzeichnis) mit einer Datei \verb'main.tf'. Der Inhalt dieser Datei ist in Listing~\ref{lst:example.tf} zu sehen und kann~\href{https://github.com/ecky-l/terraform-provider-example/blob/main/src/exampletf}{hier} im GitHub-Repository~\autocite{ecky-l_terraform-provider-example_nodate} gefunden werden.

\begin{lstlisting}[label=lst:example.tf]
terraform {
  required_providers {
    example = {
      source  = "example.com/tfp-example/example"
      version = "0.0.1"
  }
}

provider "example" {
  host = "http://localhost:8080"
}

resource "example_shop_article" "example" {
  name        = "Princess Rosalea"
  description = "Child Shampoo & Conditioner"
}
\end{lstlisting}

Jedes Terraform-Hauptmodul\footnote{Es gibt auch Untermodule, die nicht notwendigerweise alle Konfigurationsoptionen enthalten, wenn sie in anderen (Haupt-)Modulen verwendet werden.} enthält mindestens einen \verb'terraform'-Block, in dem die \emph{erforderlichen Provider} konfiguriert werden. Jeder Provider wird mit seinem Namen und der Quelle, von der er heruntergeladen werden kann, aufgeführt. Die erforderliche Version ist optional, anderenfalls wird automatisch die neueste Version ermittelt und verwendet. Anschließend folgt optional jeweils ein \verb'provider'-Block, in dem spezielle Konfigurationen übergeben werden können. Danach können die Ressourcen und Datenquellen des Providers verwendet werden.

Ein \verb'terraform init' im Verzeichnis mit den Terraform-Quellen lädt den Provider aus der angegebenen Quelle herunter und extrahiert ihn in das lokale \emph{.terraform}-Verzeichnis. Ein anschließendes \verb'terraform plan' zeigt an, was passieren wird, d.h.\ welche Ressourcen erstellt/modifiziert/gelöscht werden. Danach führt ein \verb'terraform apply' den Plan tatsächlich aus. Während dieser Befehle kommuniziert Terraform mit dem Provider und ruft eine Reihe von Funktionen auf, die im Folgenden beschrieben werden.

\subsubsection{Provider-Installation}
\label{subsubsec:prov-inst}

Der \verb'source'-Parameter im \verb'required_providers'-Block hat eine spezielle Struktur, die angibt, wo das Binär-Release des Providers zu finden ist. Er besteht aus drei Teilen:

\begin{itemize}
\item Der Domain, auf der sich das Provider-Release befindet.
\item Einem Namensraum für den Provider, meist ein Team oder Unternehmen, von dem der Provider kommt.
\item Dem Namen des Providers.
\end{itemize}

Daraus ergibt sich, dass die Quelle immer dem Schema \emph{<domain>/<namespace>/<provider name>} folgt. Die meisten Provider werden im Terraform Provider Registry~\autocite{noauthor_terraform_registry_nodate} gehostet, weshalb die Domain \emph{registry.terraform.io} für diese Provider der Einfachheit halber weggelassen werden kann. Andernfalls muss es sich um eine gültige Domain handeln, unter der ein Webserver die Provider-Binärdateien innerhalb der Verzeichnisstruktur \emph{<namespace>/<provider name>} bereitstellt. Dort müssen die Releases nach dem Schema \emph{terraform-provider-<name>\_<version>\_<arch>.zip} benannt sein. Das \emph{<name>} ist dabei derselbe Name wie in der dritten Komponente der Provider-URL, \verb'<version>' ist die Provider-Version nach semantischer Versionsnummerierung~\autocite{preston-werner_semantic_versioning_nodate} und \emph{<arch>} bezeichnet die Architektur und das Betriebssystem, für die der Provider kompiliert wurde.

Obwohl empfohlen, ist das Hosten des Providers auf einer Domain streng genommen nicht erforderlich. Alternativ kann die gezippte Binärdatei in einem lokalen Verzeichnis abgelegt und dieses als \verb'filesystem_mirror' konfiguriert werden. Der Prozess und die verschiedenen Möglichkeiten sind in~\autocite{noauthor_terraform_provider_installation_nodate} beschrieben. Die einfachste Variante besteht darin, die gezippte Binärdatei in ein Verzeichnis zu legen, das der dreiteiligen Schema-Struktur des Provider-Standorts unterhalb von \verb'~/.terraform.d/plugins/' folgt, wobei \verb'~' das Home-Verzeichnis des Benutzers ist. In unserem Beispiel mit der Version \emph{0.0.1} und unter macOS sieht dies folgendermaßen aus:

\begin{lstlisting}
/Users/<youruser>/.terraform.d/
|-- checkpoint_cache
|-- checkpoint_signature
|-- plugins
    |-- example.com
        |-- tfp-example
            |-- example
            |-- terraform-provider-example\_0.0.1\_darwin\_arm64.zip
\end{lstlisting}

Der Parameter \verb'<arch>' bezeichnet die Architektur der Plattform, für die der Provider kompiliert wurde. Um die aktuelle Architektur herauszufinden, kann man das \verb'go'-Tool selbst verwenden, da es die benötigten Werte für Architektur und Betriebssystem ausgibt. Dafür kann z.B.\ in einer Shell das folgende Kommando ausgeführt werden:

\begin{lstlisting}[language=bash,basicstyle=\ttfamily\footnotesize,numbers=none]
go version | cut -d' ' -f4 | sed -E 's/\//_/'
\end{lstlisting}

Dieser Trick ist in unserem Beispiel Teil des \verb'install'-Ziels im \href{https://github.com/ecky-l/terraform-provider-example/blob/main/src/tfp-example/Makefile}{\emph{Makefile}} das den Build- und Installationszyklus steuert. Der einfachste Weg, unseren Beispiel-Provider zu installieren, besteht darin, im geklonten Beispiel-Repository~\autocite{ecky-l_terraform-provider-example_nodate} in das Verzeichnis \verb'src/tfp-example/' zu wechseln und \verb'make install' auszuführen (eine installierte \emph{Go}-Umgebung ist Voraussetzung).

\subsubsection{Verwendung des Providers und der ``Terraform-Lebenszyklus''}
\label{subsubsec:prov-usage-terr}

Sobald der Provider installiert ist, kann er verwendet werden. Dies geschieht in den beiden wahrscheinlich am häufigsten ausgeführten Terraform-Befehlen, die in einem Terraform-Hauptmodul ausgeführt werden:

\begin{description}
\item[\texttt{terraform plan}] vergleicht den aktuellen bekannten Terraform-State mit den Ressourcendefinitionen in den \verb'.tf'-Dateien. Wenn Unterschiede bestehen, wird eine Ausgabe erzeugt, die genau angibt, was Terraform im Falle eines \emph{apply} tun wird.
\item[\texttt{terraform apply}] führt die im \emph{plan} ermittelten Änderungen aus. Zuvor werden die Änderungen in derselben Form angezeigt, und es wird eine Bestätigung verlangt (die mit dem Flag \verb'--auto-approve' unterdrückt werden kann).
\item[\texttt{terraform destroy}] löscht die Ressourcen aus dem Backend und dem Terraform-State. Auch hier ist eine Bestätigung erforderlich.
\end{description}

Um dies in Aktion zu sehen, muss \emph{wiremock} im Verzeichnis \verb'src/wiremock/' gestartet werden. Das enthaltene \verb'mappings/'-Verzeichnis enthält das Szenario für den Shop-Artikel (vgl.\ Abschnitt~\ref{sec:simple-rest-api}). Im Verzeichnis \verb'src/exampletf/' können dann die o.g.\ Terraform-Befehle ausgeführt werden. Ein \verb'terraform plan' sollte die Ausgabe aus Listing~\ref{lst:exampletfPlan} liefern.

\begin{lstlisting}[label=lst:exampletfPlan]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # example_shop_article.example will be created
  + resource "example_shop_article" "example" {
      + description = "Child Shampoo & Conditioner"
      + id          = (known after apply)
      + name        = "Princess Rosalea"
    }

Plan: 1 to add, 0 to change, 0 to destroy.

-----------------------------------------------------------------------------------------
Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform apply" now.

\end{lstlisting}

Ein anschließendes \verb'terraform apply' sollte dasselbe Ergebnis wie in Listing~\ref{lst:exampletfPlan} zeigen, ergänzt um eine zusätzliche Bestätigungsabfrage, die wortwörtlich mit ``yes'' beantwortet werden muss. Nachdem das erfolgt ist, zeigt ein anschließendes \verb'terraform plan' mit der Ausgabe in Listing~\ref{lst:exampletfPlanInSync}, dass der Terraform-State, die Ressourcendefinitionen in den \verb'.tf'-Dateien und die tatsächlichen Ressourcen im Backend synchron sind.

\begin{lstlisting}[label=lst:exampletfPlanInSync]
example_shop_article.example: Refreshing state... [name=Princess Rosalea]

No changes. Your infrastructure matches the configuration.

Terraform has compared your real infrastructure against your configuration and found no differences, so no changes are needed.
\end{lstlisting}

Nun können die Ressourcen im Modul mit einem \verb'terraform destroy' gelöscht werden, wobei die Ausgabe in Listing~\ref{lst:exampletfDestroy} gezeigt wird. Mit der wortwörtlichen Eingabe von ``yes'' werden die Ressourcen gelöscht.

\begin{lstlisting}[label=lst:exampletfDestroy]
example_shop_article.example: Refreshing state... [name=Princess Rosalea]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # example_shop_article.example will be destroyed
  - resource "example_shop_article" "example" {
      - description = "Child Shampoo & Conditioner" -> null
      - id          = 1 -> null
      - name        = "Princess Rosalea" -> null
    }

Plan: 0 to add, 0 to change, 1 to destroy.

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value:
\end{lstlisting}

Dieser ``Terraform-Lebenszyklus'' ist den meisten Lesern wahrscheinlich bekannt, da sie ihren Weg hierher gefunden haben, um mehr über die Entwicklung von Terraform-Providern zu lernen. Dennoch ist es wichtig, ihn sich während der Entwicklungsphase ins Gedächtnis zu rufen, um die Reihenfolge und Zuordnung der Callbacks in den verschiedenen Phasen herstellen zu können. Daher diese kleine Wiederholung ;-).

\subsection{The Developer's View}
\label{subsec:developers-view}

From the perspective of a provider developer, things look a little different. Nevertheless he needs to see the practitioner's view as well and it is necessary that a plugin developer knows how terraform works, let alone to manually test his implementation. The most important resource during the course of provider development is the terraform framework documentation~\autocite{noauthor_terraform_framework_nodate}, where references and guidelines for provider development can be found. Here we will have a close look at a simple but self contained provider example. We start with an overview of the source and directory structure and then describe the source files themselves. The sources are not shown here in their entirety, but are referenced from the provider example repository~\autocite{ecky-l_terraform-provider-example_nodate}. Where appropriate, small peaces are shown here as listings.

\subsubsection{Sources Structure and Development Cycle}
\label{subsubsec:prov-sourc-struct}

Every software project has some kind of structure for source and auxiliary files inside a directory, that is set up once and then does not change much. For a terraform provider this does basically follow the conventions of a go module~\autocite{noauthor_go_modules_nodate} and in our example the structure can be found \href{https://github.com/ecky-l/terraform-provider-example/tree/main/src/tfp-example}{here} in the example repository~\autocite{ecky-l_terraform-provider-example_nodate}. It looks like listing~\ref{lst:directory-structure}. The module is initialized with the command \verb'go mod init terraform-provider-<name>', with \emph{<name>} being the provider name. A sub module of directory \emph{<name>} contains the provider specific sources, here inside the \verb'example/' directory. The files \verb'go.mod' and \verb'go.sum' are managed by the \verb'go' tool and contain module dependencies and their check sums.

\begin{lstlisting}[label=lst:directory-structure]
tfp-example
|-- docs
|   |-- index.md
|-- example
|   |-- provider_test.go
|   |-- provider.go
|   |-- shop_article_resource_test.go
|   |-- shop_article_resource.go
|-- go.mod
|-- go.sum
|-- main.go
|-- Makefile
\end{lstlisting}

The special file \verb'main.go' contains the entry point for the provider. A \verb'main()' function inside it starts the provider server, with which the \verb'terraform' tool communicates during runtime via \emph{Remote Procedure Calls} (\emph{RPC}):

\begin{lstlisting}[label=lst:main]
func main() {
    providerserver.Serve(context.Background(), example.New, providerserver.ServeOpts{
        Address: "example.com/tfp-example/example",
    })
}
\end{lstlisting}

During the development cycle it is frequently necessary to compile, test and install the latest binary. We use a \emph{Makefile} to ease the burden of these frequent cycles, which takes care of compressing and installing the binary in the directory mentioned in Section~\ref{subsubsec:prov-inst}. To do this, you can just type \verb'make install' inside the \verb'tfp-example' directory.

\subsubsection{The Provider and its Configuration}
\label{subsubsec:base-prov-conf}

Most providers do usually communicate with some kind of backend and must be configured appropriately to perform this functionality. From the practitioner's point of view (see Section~\ref{subsec:practitioners-view}) this is done with the \verb'provider' block. For a particular provider this block contains all configurable parameters and their values. From the provider developers point of view, the provider looks like the \verb'example/provider.go' file and it contains a few specific implementations.

A provider in the developers view is a structure that implements various methods from the terraform plugin framework~\autocite{noauthor_terraform_framework_nodate}. In our case this is the \verb'exampleProvider' struct:

\begin{lstlisting}
type exampleProvider struct {
	host string
}
\end{lstlisting}

This struct is passed as a receiver to the implementing methods in \verb'provider.go'. A concrete value is created with the \verb'New()' function, which in turn is passed to the \verb'providerserver.Serve()' method in listing~\ref{lst:main} and must therefore return a \verb'provider.Provider' interface type that implicitly implements all the methods for that interface. For this reason the go compiler enforces the implementation of all the necessary methods, which can be seen in \verb'provider.go'.

\begin{description}
\item[Metadata()] returns the provider name.
\item[Schema()] specifies and returns the parameters that can be configured in the \verb'provider' block for the resource (see listing~\ref{lst:example.tf}).
\item[Configure()] is called when a \verb'provider' block occurs in the \verb'.tf' sources and must take care of reading, validating and storing the values for the configurable parameters. In our example there is only one parameter \emph{host}. We check whether it is a valid URL and store it in the \verb'host' field in the provider struct receiver. Typically the configured values must be passed to the provider's resources later on, and this is done via fields in the \verb'provider.ConfigureResponse' pointer argument that is passed to \verb'Configure()'. We will see later, how values are retrieved during resource or data source configuration.
\item[DataSources()] returns a list of functions that create the \verb'data' source blocks, which are implemented by the provider.
  \item[Resources()] returns a list of functions that create the \verb'resource' blocks, which are implemented by the provider.
\end{description}

The return arguments of the latter two methods must be lists of functions, which create \verb'datasource.DataSource' and \verb'resource.Resource' go interface types respectively. They specify methods which must be implemented for the respective \verb'data' and \verb'resource' blocks, and are called during the lifecycle of a terraform run.

\subsubsection{A Word on Testing}
\label{subsubsec:note-on-testing}

It is good practice to start the implementation of any functionality with a unit- or integration test. Not only enforces this that we need to think about the design and implementation details itself - it also helps to test the implementation right from the beginning, by debugging from the test into the logic, and to mitigate regressions later on when the project evolves. The terraform SDK provides a testing framework~\autocite{noauthor_terraform_acceptance_testing_nodate}, which can be utilized in a comfortable manner to test all aspects in the lifecycle of a terraform run. At its core there is a call to \verb'resource.Test' or \verb'resource.UnitTest' inside an ordinary Go test with a \verb'resource.TestCase' as argument. This test case contains a list of steps that are executed in order with an internally maintained ephemeral state. The sequence of the test steps would closely resemble how a practitioner runs terraform on his infrastructure and \emph{tfstate} in the course of time: first he creates resources, then eventually updates these resources and then at some point later he deletes the resources again. In a terraform framework \verb'resource.TestCase' the deletion is done automatically as a last implicit step. Another optional step is to import existing resources by ID into the terraform state, which can also be covered.

A unit test for our resource, which is described in Section~\ref{subsec:emphsh-reso}, can be found \href{https://github.com/ecky-l/terraform-provider-example/blob/main/src/tfp-example/example/shop_article_resource_test.go}{here}. It defines two steps in one test case, which create and update a \emph{shop\_article} resource, and implicitly delete it afterwards. At each step there are checks defined, which verify that the corresponding resource parameters have been set correctly. If you set up such a test right from the beginning when developing a resource, you can put break points inside the callback functions that are called during the test run and step into these callback functions to get their implementation right. Modern \emph{Integrated Development Environments} (\emph{IDE}s) allow you to run and debug tests directly on click with changed sources. This is much simpler than building and installing the provider each time, and then running terraform from the command line to identify bugs solely by log messages, or trial \& error.

There are two ways to test the code. A \verb'resource.UnitTest' is always executed when \verb'go test' is called. Care must be taken when the code communicates with an actual backend: then the resources are indeed created in this backend, which might not be what you want. Therefore there is a second function \verb'resource.Test', which is only executed when the environment variable \verb'TF_ACC' is set. Although the difference is small, it is good practice to use unit tests with mocked backends, where no actual resources are created, and acceptance tests with real backends, when the real integration with the terraform provider is to be verified. For mocked backends there are several strategies. One is to use tools like \emph{Wiremock}~\autocite{noauthor_wiremock_nodate}, that pretend to be a backend but just return artificial responses. Another is to use a mock implementation of the backend calling library type, i.e. \verb'http.Client', and a mocking framework, i.e. \emph{testify/mock}~\autocite{noauthor_testifymock_nodate}, to specify exact responses for certain calls on the mock. \verb'Go''s implicit interface implementation can help to create mocks for any, even library types that are outside the developer's control.

Although the second option is appealing, as it does not require any other tools and processes to be run, we follow the first approach and use \emph{Wiremock} in this example. The advantage is it's simplicity - responses can just be defined by JSON files in the \verb'mappings/' directory (see Section~\ref{sec:simple-rest-api}). At a downside, \verb'wiremock' must always be started in the background and listen for connections when tests are run, and it must be in the correct state.

\subsubsection{The \emph{shop\_article} Terraform Resource}
\label{subsec:emphsh-reso}

For our example we implement one resource with the name \emph{example\_shop\_article}. The corresponding implementation is in \href{https://github.com/ecky-l/terraform-provider-example/blob/main/src/tfp-example/example/shop_article_resource.go}{this file} in the example repository~\autocite{ecky-l_terraform-provider-example_nodate}. In this section will see a short description of this file.

As with the provider itself, each resource is represented by a \emph{struct} and can contain arbitrary data. For our example the resources struct looks like the one in listing~\ref{lst:shopArticleResource}.

\begin{lstlisting}[label=lst:shopArticleResource]
type shopArticleResource struct {
	provider *exampleProvider
}
\end{lstlisting}

Its only field is a pointer to the provider struct value, to which it belongs. This field is filled during the terraform lifecycle in the \verb'Configure()' method of the resource struct as described below. Another struct, in our example called \verb'shopArticleResourceModel', represents a concrete resource of that type with corresponding values. This struct is instantiated for each concrete resource of the resource type and passed from and to the terraform provider \verb'request' and \verb'response' arguments in the callbacks. It serves for two things:

\begin{description}
\item[The \emph{plan}] is the desired resources state when the terraform lifecycle is finished. It is determined from the \verb'.tf' files in a terraform module and contains the parameters for the resource ``to be''.
\item[The \emph{state}] is the resource that \emph{exists} in the terraform state due to prior creation or modification. An empty state is created for a resource that not (yet) exists.
\end{description}

When a \verb'terraform plan' is executed by the practitioner, the plan and state values for each resource are compared and divergences are determined. If no divergences exist, the terraform lifecycle finishes with an appropriate message. Otherwise terraform shows what needs to be done to bring the state in sync with the plan for that resource. In our example the resource model struct is shown in listing~\ref{lst:shopArticleResourceModel}.

\begin{lstlisting}[label=lst:shopArticleResourceModel]
type shopArticleResourceModel struct {
	ID          types.Int64  `tfsdk:"id"`
	Name        types.String `tfsdk:"name"`
	Description types.String `tfsdk:"description"`
}
\end{lstlisting}

The \verb'`tfsdk:*`' directives after each field indicate which parameters in the \emph{resource schema} are to be used for the field value. They ensure that the values in a resource definition, like the one in listing~\ref{lst:example.tf}, are put into the fields of the \emph{plan} for that resource.

A function that returns an instance of the struct must be listed in the return value of the \verb'Resources()' method of the provider (see Section~\ref{subsubsec:base-prov-conf}) in order to actually hook the resource in. This enforces that the resource's struct implements a set of methods, namely:

\begin{description}
\item[Metadata()] is called by terraform to determine meta data of the resource block. Most notably it registers the name of the resource, such that a resource definition like in listing~\ref{lst:example.tf} is possible.
\item[Configure()] is called when terraform encounters a \verb'resource' block of the respective type. In this callback it is possible to pass provider parameters to the resource struct. In our example resource we set a pointer to the provider struct into the resource, by which we can later refer to the backend host. More parameters are possible as needed.
\item[Schema()] is called to determine which parameters are possible for the resource. It returns a defined \verb'schema.Schema' value with the possible parameters of the resource and its constraints. In our example, note the \verb'PlanModifiers' setting. By specifying the \verb'RequiresReplace' plan modifier, the resource would be deleted and re-created if the practitioner changes its name. Other such plan modifiers are possible and can even be self-implemented.
\item[Create()] is called when terraform determines that a declared resource must be created. This callback must implement the creation of the entity in the backend. In our case we issue a \verb'POST' call to our web service to create a shop article. Afterwards the parameters of the newly created resource must be set to the state model and the state must be updated in the \emph{response} argument of the callback.
\item[Delete()] is called when terraform determines that a resource must be deleted. This is the case either when \verb'terraform destroy' has been called or the resource declaration is not present anymore in the terraform module. The callback must implement the deletion of the resource in the backend, in our case we issue a \verb'DELETE' request to our web service.
\item[Read()] is called when terraform needs to determine the backend state of a declared resource. This is the case either when the resource is to be imported, or in order to synchronize the terraform state with the backend state. When talking to a REST web service, the callback does usually implement a \verb'GET' call to retrieve the backing entity of the resource, i.e.\ by ID.\ We call \verb'GET /articles/<id>' to retrieve the shop article from the web service and update the state values in the \emph{response} argument of the callback.
  \item[Update()] is called when the terraform \emph{plan} (the resource value that has been determined from the \verb'.tf' files) diverges from the terraform \emph{state}. In this case the backend entity must eventually be updated and the callback must implement the corresponding logic. In our example we determine the plan's new description value and send a \verb'PUT' call with an appropriate JSON payload to our backend to update the entity.
\end{description}

The methods do closely interact with their arguments. As you can see, the \verb'response' arguments are pointers to various types inside the terraform provider framework. The intend behind this is that values inside the response are meant to be updated by the callback, for instance should the resource state with updated values be set into the response.

\paragraph{Error Handling}

The response argument to the callbacks does also contain a field called \verb'Diagnostics'. It serves as a storage for information that is formatted and displayed to the practitioner during the terraform lifecycle and is particularly useful for error messages. Therefore the error handling is done frequently by a call to \verb'response.Diagnostics.AddError()', like in listing~\ref{lst:errorHandling} for JSON unmarshalling.

\begin{lstlisting}[label=lst:errorHandling]
if err := dec.Decode(&respBody); err != nil {
    resp.Diagnostics.AddError("Error during article Create", fmt.Sprintf("Json unmarshalling error: %v", err))
    return
}
\end{lstlisting}

If the caught error occures, the practitioner would see the appropriate message:

\begin{lstlisting}
...
example_shop_article.example: Creating...
|
| Error: Error during article Create
|
|   with example_shop_article.example,
|   on main.tf line 14, in resource "example_shop_article" "example":
|   14: resource "example_shop_article" "example" {
|
| Json unmarshalling error: unexpected EOF
|
\end{lstlisting}

The callback implementations for our example are quite simple. Normally one would encapsulate the backend calls in a helper function or object, instead of repeating the code in every callback function, and also do more advanced error handling. But for demonstration purposes it is just fine to have it that direct way.

\section{Summary}
\label{sec:summary}

Sometimes it is necessary to maintain infrastructure as code with terraform for resources, which are not supported out of the box - be it because they are self-developed, or for other reasons. Terraform has a powerful plugin mechanism and well documented SDK, that enables the development of own in-house providers for such cases.

In this article we have introduced the terraform provider framework by using a small, self contained and illustrative example. A terraform provider ``example'' is developed with one resource \emph{shop\_article} that is backed by an artificial REST backend, provided by a \emph{Wiremock scenario}. We have seen how the overall code can be structured, how development versions of a provider can be installed, used and tested, including tips and best practices to use the terraform testing framework.

A accompanying \emph{DataSource} for the \emph{shop\_article} entity is not part of this example. But this is not very complicated after following this article and looking at the sources, so it is left for encouraged readers as an exercise.

\printbibliography[heading=bibintoc]

\end{document}
